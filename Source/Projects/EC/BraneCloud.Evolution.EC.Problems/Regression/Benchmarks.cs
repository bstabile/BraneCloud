using System;
using System.Collections.Generic;

using BraneCloud.Evolution.EC.Configuration;
using BraneCloud.Evolution.EC.GP;
using BraneCloud.Evolution.EC.GP.Koza;
using BraneCloud.Evolution.EC.Simple;
using BraneCloud.Evolution.EC.Support;

/*
 * Benchmarks by various people in the literature.
 *
 */

namespace BraneCloud.Evolution.EC.Problems.Regression
{
    /// <summary>
    /// * Benchmarks.java
    /// * U    
    /// * Created: Thu Jul 14 10:35:11 EDT 2011
    /// * By: Sean Luke
    /// *
    /// * This is an expansion of the Regression.java file to provide a first cut at a standardized
    /// * regression benchmark for Genetic Programming.  The package provides both training and
    /// * testing data and functions for the following problems:
    /// 
    /// <ol>
    /// <li>John Koza's three  problems (quartic, quintic, and sextic, drawn from his GP-1 and GP-2 books.  These are known as <b>koza-1</b> through <b>koza-3</b></li>
    /// <li>Twelve problems drawn from "Semantically-based Crossover in Genetic Programming: Application to Real-valued Symbolic Regression" (GPEM 2011),
    /// by Nguyen Quang Uy, Nguyen Xuan Hoai, Michael O’Neill, R.I. McKay, Edgar Galv ́an-L ́opez.  These are known as
    /// <b>nguyen-1</b> through <b>nguyen-12</b></li>
    /// <li>Fifteen problems drawn from "Accuracy in Symbolic Regression" (GPEM 2011), by Michael Korns.  These are known as <b>KORNS1</b> through <b>KORNS15</b></li>
    /// <li>Fifteen problems drawn from "Improving Symbolic Regression with Interval Arithmetic and Linear Scaling" (EuroGP 2003), by Maarten Keijzer.  These are known as <b>keijzer-1</b> through <b>keijzer-15</b></li>
    /// <li>Fifteen problems drawn from "Order of Nonlinearity as a Complexity Measure for Models Generated by Symbolic Regression via Pareto Genetic Programming" (IEEE TransEC 13:2), by Ekaterina J. Vladislavleva, Guido F. Smits, and Dick den Hertog.  These are known as <b>vladislavleva-1</b> through <b>vladislavleva-8</b></li>
    /// <li>Two problems drawn from "Evolutionary Consequences of Coevolving Targets" (Evolutionary Computation 5(4)) by Ludo Pagie and Paulien Hogeweg, 1997.</li>
    /// <li>You can also provide your own data sets via a text file.</li>
    ///
    /// <p/>These problems differ in a variety of ways.  Some have both training and testing data points.  Some have one variable, others up to five variables.  Some build their random points based on random samples, other based on a grid of samples distributed through the space.  Different problems also use different function sets.
    /// 
    /// <p/>The functions below are all described precisely in the paper "Genetic Programming Needs Better Benchmarks" (GECCO 2012) by James McDermmott, David R. white, Sean Luke, Luca Manzoni, Mauro Castelli, Leonardo Vanneschi, Wojciech Jaskowski, Krzysztof Krawiec, Robin Harper, Kenneth De Jong, and Una-May O'Reilly.  The descriptions, shown in Tables 2 and 3, explain the function set, number of variables, objective function, training set, testing set, and source of each problem.
    /// 
    /// <p/>In addition we include one more function: PAGIE2, a 3-variable version of PAGIE1. We describe PAGIE2 as follows:
    /// </ol>
    /// <ul>
    /// <li>Variables: 3</li>
    /// li>Function: (1 / (1 + x^(-4)) + 1 / (1 + y^(-4)) + 1 / (1 + z^(-4)))</il>
    /// <li>Testing Set: Grid points from -5 to 5 respectively in each dimension, spaced out in intervals of 0.4.</li>
    /// <li>Training Set: none</li>
    /// <li>Function Set: standard Koza with three terminals (X1, X2, X3).</li>
    /// </ul>
    ///
    /// </summary>
    [ECConfiguration("ec.problems.regression.Benchmarks")]
    public class Benchmarks : GPProblem, ISimpleProblem
    {

        #region Problem Tags

        // From GP-1 and GP-2
        public const int KOZA1 = 0;
        public const int KOZA2 = 1;
        public const int KOZA3 = 2;

        // From Semantically-based Crossover in Genetic Programming: Application to Real-valued Symbolic Regression
        // Nguyen Quang Uy, Nguyen Xuan Hoai, Michael O’Neill, R.I. McKay, Edgar Galv ́an-L ́opez
        // GPEM 2011
        public const int NGUYEN1 = 3;
        public const int NGUYEN2 = 4;  // identical to standard Koza
        public const int NGUYEN3 = 5;
        public const int NGUYEN4 = 6;
        public const int NGUYEN5 = 7;
        public const int NGUYEN6 = 8;
        public const int NGUYEN7 = 9;
        public const int NGUYEN8 = 10;
        public const int NGUYEN9 = 11;
        public const int NGUYEN10 = 12;
        public const int NGUYEN11 = 13;
        public const int NGUYEN12 = 14;

        // From Pagie and Hogeweg 1997: Ludo Pagie, Paulien Hogeweg: Evolutionary Consequences of Coevolving
        // Targets. Evolutionary Computation 5(4): 401-418 (1997).
        public const int PAGIE1 = 15;        // 2D
        public const int PAGIE2 = 16;        // 3D

        // From Accuracy in Symbolic Regression -- GPTP 2011
        public const int KORNS1 = 17;
        public const int KORNS2 = 18;
        public const int KORNS3 = 19;
        public const int KORNS4 = 20;
        public const int KORNS5 = 21;
        public const int KORNS6 = 22;
        public const int KORNS7 = 23;
        public const int KORNS8 = 24;
        public const int KORNS9 = 25;
        public const int KORNS10 = 26;
        public const int KORNS11 = 27;
        public const int KORNS12 = 28;
        public const int KORNS13 = 29;
        public const int KORNS14 = 30;
        public const int KORNS15 = 31;

        // From Improving Symbolic Regression with Interval Arithmetic and Linear Scaling
        // Maarten Keijzer -- EuroGP 2003
        public const int KEIJZER1 = 32;
        public const int KEIJZER2 = 33;
        public const int KEIJZER3 = 34;
        public const int KEIJZER4 = 35;
        public const int KEIJZER5 = 36;
        public const int KEIJZER6 = 37;
        public const int KEIJZER7 = 38;
        public const int KEIJZER8 = 39;
        public const int KEIJZER9 = 40;
        public const int KEIJZER10 = 41;
        public const int KEIJZER11 = 42;
        public const int KEIJZER12 = 43;
        public const int KEIJZER13 = 44;
        public const int KEIJZER14 = 45;
        public const int KEIJZER15 = 46;

        // From Order of Nonlinearity as a Complexity Measure for Models Generated by Symbolic Regression via Pareto Genetic Programming
        // Ekaterina J. Vladislavleva, Guido F. Smits, and Dick den Hertog
        public const int VLADISLAVLEVA1 = 47;
        public const int VLADISLAVLEVA2 = 48;
        public const int VLADISLAVLEVA3 = 49;
        public const int VLADISLAVLEVA4 = 50;
        public const int VLADISLAVLEVA5 = 51;
        public const int VLADISLAVLEVA6 = 52;
        public const int VLADISLAVLEVA7 = 53;
        public const int VLADISLAVLEVA8 = 54;

        #endregion // Problem Tags

        #region Arrays : names, fs, fs_vars

        // parameter names
        public static readonly String[] names = 
        { 
        "koza-1", "koza-2", "koza-3",
        "nguyen-1", "nguyen-2", "nguyen-3", "nguyen-4", "nguyen-5", "nguyen-6", "nguyen-7", "nguyen-8", "nguyen-9", "nguyen-10", "nguyen-11", "nguyen-12",
        "pagie-1", "pagie-2",
        "korns-1", "korns-2", "korns-3", "korns-4", "korns-5", "korns-6", "korns-7", "korns-8", "korns-9", "korns-10", "korns-11", "korns-12", "korns-13", "korns-14", "korns-15",
        "keijzer-1", "keijzer-2", "keijzer-3", "keijzer-4", "keijzer-5", "keijzer-6", "keijzer-7", "keijzer-8", "keijzer-9", "keijzer-10", "keijzer-11", "keijzer-12", "keijzer-13", "keijzer-14", "keijzer-15", 
        "vladislavleva-1", "vladislavleva-2", "vladislavleva-3", "vladislavleva-4", "vladislavleva-5", "vladislavleva-6", "vladislavleva-7", "vladislavleva-8"
        };


        // expected function sets.  "fn" means "function set with n terminals x_1 ... x_n"
        public static readonly String[] fs = 
        {
        "koza1", "koza1", "koza1",
        "koza1", "koza1", "koza1", "koza1", "koza1", "koza1", "koza1", "koza1", "koza2", "koza2", "koza2", "koza2",
        "koza2", "koza3",
        "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", "korns5", 
        "keijzer1", "keijzer1", "keijzer2", "keijzer1", "keijzer3", "keijzer1", "keijzer1", "keijzer1", "keijzer1", "keijzer2", "keijzer2", "keijzer2", "keijzer2", "keijzer2", "keijzer2",
        "vladislavleva-b2", "vladislavleva-c1", "vladislavleva-c2", "vladislavleva-a5", "vladislavleva-a3", "vladislavleva-b2", "vladislavleva-c2", "vladislavleva-a2"
        };



        // function sets with various variable lengths
        public static readonly IList<string[]> fs_vars = new List<string[]>
                                                             {
                                                                 new string[0],
                                                                 new[] {"koza1", "keijzer1", "vladislavleva-c1"},
                                                                 new[]
                                                                     {
                                                                         "koza2", "keijzer2", "vladislavleva-a2",
                                                                         "vladislavleva-b2", "vladislavleva-c2"
                                                                     },
                                                                 new[] {"koza3", "keijzer3", "vladislavleva-a3"},
                                                                 new String[0],
                                                                 new[] {"korns5", "vladislavleva-a5"},
                                                             };

        #endregion // Arrays

        #region Input Sample Generation

        /* Produce random sample points between min and max, inclusive, in each dimension.  */
        public double[][] generateRandomSamples(IEvolutionState state, double[] min, double[] max, int numPoints, int threadnum)
        {
            var vars = max.Length;
            var d = new double[numPoints][];
            for (var i = 0; i < numPoints; i++)
                d[i] = new double[vars];
            for (var i = 0; i < d.Length; i++)
                for (var j = 0; j < vars; j++)
                    // below we're doing nextDouble(true, true), which means to select from the
                    // FULLY CLOSED interval [0.0, 1.0], including both 0.0 and 1.0.
                    d[i][j] = state.Random[threadnum].NextDouble(true, true) * (max[j] - min[j]) + min[j];
            return d;
        }

        /* Produce random sample points between min and max, inclusive, in one dimension.  */
        public double[][] generateRandomSamples(IEvolutionState state, double min, double max, int numPoints, int threadnum)
        {
            return generateRandomSamples(state, new[] { min }, new[] { max }, numPoints, threadnum);
        }

        /*

            // recursive trick to dump the full mesh into a bag.  Enter this by setting variable to 0,  Yuck, expensive.  But O(n).
            void buildIntervalPoints(EvolutionState state, List<double[]> list, double[] min, double[] max, double[] interval, double current[], int variable, int threadnum)
                {
                if (variable == min.length)  // we're out of variables, base case
                    {
                    double[] d = new double[min.length];
                    for(int i = 0; i < d.length; i++)
                        d[i] = current[i];      // not sure if System.arraycopy would be faster, probably not in this case 
                    list.add(d);
                    }
                else
                    {
                    for(double pos = min[variable]; pos <= max[variable]; pos += interval[variable])         // for each interval
                        {
                        current[variable] = pos;
                        buildIntervalPoints(state, list, min, max, interval, current, variable + 1, threadnum);
                        }
                    }
                }
        */

        // recursive trick to dump the full mesh into a bag.  Enter this by setting variable to 0,  Yuck, expensive.  But O(n).
        void buildIntervalPoints(IEvolutionState state, IList<double[]> list, IList<double> min, IList<double> max, IList<double> interval, IList<double> current, int variable, int threadnum)
        {
            if (variable == min.Count)  // we're out of variables, base case
            {
                var d = new double[min.Count];
                for (var i = 0; i < d.Length; i++)
                    d[i] = current[i];      // not sure if System.arraycopy would be faster, probably not in this case
                list.Add(d);
            }
            else
            {
                var jumps = (int)((max[variable] - min[variable]) / interval[variable]) + 1;

                for (var j = 0; j < jumps; j++)
                {
                    current[variable] = min[variable] + interval[variable] * j;
                    buildIntervalPoints(state, list, min, max, interval, current, variable + 1, threadnum);
                }
            }
        }

        /* Produce sample points evenly spaced out between min and max in each dimension, with the given spacing interval per-dimension.  */
        public double[][] generateIntervalSpacedSamples(IEvolutionState state, double[] min, double[] max, double[] interval, int threadnum)
        {
            // gather all the points in the mesh recursively
            var list = new List<double[]>();
            var current = new double[min.Length];
            buildIntervalPoints(state, list, min, max, interval, current, 0, threadnum);

            // Convert to an array
            return list.ToArray();
        }

        /* Produce sample points evenly spaced out between min and max in one dimension, with the given spacing interval.  One dimension only. */
        public double[][] generateIntervalSpacedSamples(IEvolutionState state, double min, double max, double interval, int threadnum)
        {
            return generateIntervalSpacedSamples(state, new[] { min }, new[] { max }, new[] { interval }, threadnum);
        }

        /* Produce sample points for a given benchmark problem.  */
        public double[][] trainPoints(IEvolutionState state, int benchmark, int threadnum)
        {
            switch (benchmark)
            {
                case KOZA1:
                case KOZA2:
                case KOZA3:
                    return generateRandomSamples(state, -1, 1, 20, threadnum);

                case NGUYEN1:
                case NGUYEN2:
                case NGUYEN3:
                case NGUYEN4:
                case NGUYEN5:
                case NGUYEN6:
                    return generateRandomSamples(state, -1, 1, 20, threadnum);

                case NGUYEN7:
                    return generateRandomSamples(state, 0, 2, 20, threadnum);

                case NGUYEN8:
                    return generateRandomSamples(state, 0, 4, 20, threadnum);

                case NGUYEN9:
                case NGUYEN10:
                case NGUYEN11:
                case NGUYEN12:
                    return generateRandomSamples(state, new double[] { 0, 0 }, new double[] { 1, 1 }, 100, threadnum);

                case PAGIE1:
                    return generateIntervalSpacedSamples(state, new[] { -5.0, -5.0 }, new[] { 5.0, 5.0 }, new[] { 0.4, 0.4 }, threadnum);
                case PAGIE2:
                    return generateIntervalSpacedSamples(state, new[] { -5.0, -5.0, -5.0 }, new[] { 5.0, 5.0, 5.0 }, new[] { 0.4, 0.4, 0.4 }, threadnum);


                case KORNS1:
                case KORNS2:
                case KORNS3:
                case KORNS4:
                case KORNS5:
                case KORNS6:
                case KORNS7:
                case KORNS8:
                case KORNS9:
                case KORNS10:
                case KORNS11:
                case KORNS12:
                case KORNS13:
                case KORNS14:
                case KORNS15:
                    return generateRandomSamples(state, new double[] { -50, -50, -50, -50, -50 }, new double[] { 50, 50, 50, 50, 50 }, 10000, threadnum);  // 10000 !!

                case KEIJZER1:
                    return generateIntervalSpacedSamples(state, -1, 1, 0.1, threadnum);

                case KEIJZER2:
                    return generateIntervalSpacedSamples(state, -2, 2, 0.1, threadnum);

                case KEIJZER3:
                    return generateIntervalSpacedSamples(state, -3, 3, 0.1, threadnum);

                case KEIJZER4:
                    return generateIntervalSpacedSamples(state, 0, 10, 0.05, threadnum);

                case KEIJZER5:
                    return generateRandomSamples(state, new double[] { -1, -1, 1 }, new double[] { 1, 1, 2 }, 1000, threadnum);

                case KEIJZER6:
                    return generateIntervalSpacedSamples(state, 1, 50, 1, threadnum);

                case KEIJZER7:
                    return generateIntervalSpacedSamples(state, 1, 100, 1, threadnum);
                case KEIJZER8:
                case KEIJZER9:
                    return generateIntervalSpacedSamples(state, 0, 100, 1, threadnum);

                case KEIJZER10:
                    return generateRandomSamples(state, new double[] { 0, 0 }, new double[] { 1, 1 }, 100, threadnum);

                case KEIJZER11:
                case KEIJZER12:
                case KEIJZER13:
                case KEIJZER14:
                case KEIJZER15:
                    return generateRandomSamples(state, new double[] { -3, -3 }, new double[] { 3, 3 }, 20, threadnum);

                case VLADISLAVLEVA1:
                    return generateRandomSamples(state, new[] { 0.3, 0.3 }, new double[] { 4, 4 }, 100, threadnum);

                case VLADISLAVLEVA2:
                    return generateIntervalSpacedSamples(state, 0.05, 10, 0.1, threadnum);

                case VLADISLAVLEVA3:
                    return generateIntervalSpacedSamples(state, new[] { 0.05, 0.05 }, new[] { 10, 10.05 }, new[] { 0.1, 2 }, threadnum);

                case VLADISLAVLEVA4:
                    return generateRandomSamples(state, new[] { 0.05, 0.05, 0.05, 0.05, 0.05 }, new[] { 6.05, 6.05, 6.05, 6.05, 6.05 }, 1024, threadnum);

                case VLADISLAVLEVA5:
                    return generateRandomSamples(state, new[] { 0.05, 1, 0.05 }, new double[] { 2, 2, 2 }, 300, threadnum);

                case VLADISLAVLEVA6:
                    return generateRandomSamples(state, new[] { 0.1, 0.1 }, new[] { 5.9, 5.9 }, 30, threadnum);

                case VLADISLAVLEVA7:
                    return generateRandomSamples(state, new[] { 0.05, 0.05 }, new[] { 6.05, 6.05 }, 300, threadnum);

                case VLADISLAVLEVA8:
                    return generateRandomSamples(state, new[] { 0.05, 0.05 }, new[] { 6.05, 6.05 }, 50, threadnum);

                default:
                    return null;
            }
        }

        /* Produce test sample points for a given benchmark problem, to test generalization.  */
        public double[][] testPoints(IEvolutionState state, int benchmark, int threadnum, double[][] trainpoints)
        {
            switch (benchmark)
            {
                case KOZA1:
                case KOZA2:
                case KOZA3:
                    return trainpoints;

                case NGUYEN1:
                case NGUYEN2:
                case NGUYEN3:
                case NGUYEN4:
                case NGUYEN5:
                case NGUYEN6:
                case NGUYEN7:
                case NGUYEN8:
                case NGUYEN9:
                case NGUYEN10:
                case NGUYEN11:
                case NGUYEN12:
                    return trainpoints;

                case PAGIE1:
                case PAGIE2:
                    return trainpoints;

                case KORNS1:
                case KORNS2:
                case KORNS3:
                case KORNS4:
                case KORNS5:
                case KORNS6:
                case KORNS7:
                case KORNS8:
                case KORNS9:
                case KORNS10:
                case KORNS11:
                case KORNS12:
                case KORNS13:
                case KORNS14:
                case KORNS15:
                    return generateRandomSamples(state, new double[] { -50, -50, -50, -50, -50 }, new double[] { 50, 50, 50, 50, 50 }, 10000, threadnum);  // 10000 !!

                case KEIJZER1:
                    return generateIntervalSpacedSamples(state, -1, 1, 0.001, threadnum);

                case KEIJZER2:
                    return generateIntervalSpacedSamples(state, -2, 2, 0.001, threadnum);

                case KEIJZER3:
                    return generateIntervalSpacedSamples(state, -3, 3, 0.001, threadnum);

                case KEIJZER4:
                    return generateIntervalSpacedSamples(state, 0.05, 10.05, 0.05, threadnum);

                case KEIJZER5:
                    return generateRandomSamples(state, new double[] { -1, -1, 1 }, new double[] { 1, 1, 2 }, 10000, threadnum);  // 10000 cases for testing, different than for training

                case KEIJZER6:
                    return generateIntervalSpacedSamples(state, 1, 120, 1, threadnum);

                case KEIJZER7:
                    return generateIntervalSpacedSamples(state, 1, 100, 0.1, threadnum);
                case KEIJZER8:
                case KEIJZER9:
                    return generateIntervalSpacedSamples(state, 0, 100, 0.1, threadnum);

                case KEIJZER10:
                    return generateIntervalSpacedSamples(state, new double[] { 0, 0 }, new double[] { 1, 1 }, new[] { 0.01, 0.01 }, threadnum);

                case KEIJZER11:
                case KEIJZER12:
                case KEIJZER13:
                case KEIJZER14:
                case KEIJZER15:
                    return generateIntervalSpacedSamples(state, new[] { -3.0, -3.0 }, new[] { 3.0, 3.0 }, new[] { 0.01, 0.01 }, threadnum);

                case VLADISLAVLEVA1:
                    return generateIntervalSpacedSamples(state, new[] { -0.2, -0.2 }, new[] { 4.2, 4.2 }, new[] { 0.1, 0.1 }, threadnum);

                case VLADISLAVLEVA2:
                    return generateIntervalSpacedSamples(state, -0.5, 10.5, 0.05, threadnum);

                case VLADISLAVLEVA3:
                    return generateIntervalSpacedSamples(state, new[] { -0.5, -0.5 }, new[] { 10.5, 10.5 }, new[] { 0.05, 0.5 }, threadnum);  // note 0.05 and 0.5, and also 10.5 which is different from training

                case VLADISLAVLEVA4:
                    return generateRandomSamples(state, new[] { -0.25, -0.25, -0.25, -0.25, -0.25 }, new[] { 6.35, 6.35, 6.35, 6.35, 6.35 }, 5000, threadnum);

                case VLADISLAVLEVA5:
                    return generateIntervalSpacedSamples(state, new[] { -0.05, 0.95, -0.05 }, new[] { 2.1, 2.05, 2.1 }, new[] { 0.15, 0.15, 0.1 }, threadnum);  // note 0.05 and 0.5, and also 10.5 which is different from training

                case VLADISLAVLEVA6:
                    return generateIntervalSpacedSamples(state, new[] { -0.05, -0.05 }, new[] { 6.05, 6.05 }, new[] { 0.02, 0.02 }, threadnum);  // note 0.05 and 0.5, and also 10.5 which is different from training

                case VLADISLAVLEVA7:
                    return generateRandomSamples(state, new[] { -0.25, -0.25 }, new[] { 6.35, 6.35 }, 1000, threadnum);

                case VLADISLAVLEVA8:
                    return generateIntervalSpacedSamples(state, new[] { -0.25, -0.25 }, new[] { 6.35, 6.35 }, new[] { 0.2, 0.2 }, threadnum);  // note 0.05 and 0.5, and also 10.5 which is different from training

                default:
                    return null;
            }
        }

        /* Return the function applied to the given data by benchmark problem.  */
        public double func(IEvolutionState state, double[] xs, int benchmark) // throws IllegalArgumentException
        {
            var x = xs[0];
            var y = (xs.Length > 1 ? xs[1] : 0);
            var z = (xs.Length > 2 ? xs[2] : 0);

            switch (benchmark)
            {
                case KOZA1:
                    return x * x * x * x + x * x * x + x * x + x;       // traditional
                case KOZA2:
                    return x * x * x * x * x - 2.0 * x * x * x + x;       // Quintic, from  J. R. Koza, GP II, 1994
                case KOZA3:
                    return x * x * x * x * x * x - 2.0 * x * x * x * x + x * x;  // Sextic, from J. R. Koza, GP II, 1994
                case NGUYEN1:
                    return x * x * x + x * x + x;
                case NGUYEN2:                                                   // identical to KOZA1
                    return x * x * x * x + x * x * x + x * x + x;
                case NGUYEN3:
                    return x * x * x * x * x + x * x * x * x + x * x * x + x * x + x;
                case NGUYEN4:
                    return x * x * x * x * x * x + x * x * x * x * x + x * x * x * x + x * x * x + x * x + x;
                case NGUYEN5:
                    return Math.Sin(x * x) * Math.Cos(x) - 1.0;
                case NGUYEN6:
                    return Math.Sin(x) + Math.Sin(x * x + x);
                case NGUYEN7:
                    return Math.Log(x + 1) + Math.Log(x * x + 1.0);
                case NGUYEN8:                           // Note this presumes you don't have sqrt(x) in your function set!
                    return Math.Sqrt(x);
                case NGUYEN9:
                    return Math.Sin(x) + Math.Sin(y * y);
                case NGUYEN10:
                    return 2 * Math.Sin(x) * Math.Cos(y);
                case NGUYEN11:
                    return Math.Pow(x, y);
                case NGUYEN12:
                    return x * x * x * x - x * x * x + (y * y) / 2.0 - y;
                case PAGIE1:
                    // otherwise known as 1 / (1 + Math.pow(x,-4)) + 1 / (1 + Math.pow(y,-1))
                    return 1.0 / (1.0 + 1.0 / (x * x * x * x)) + 1.0 / (1.0 + 1.0 / (y * y * y * y));
                case PAGIE2:
                    // otherwise known as (1 / (1 + Math.pow(x, -4)) + 1 / (1 + Math.pow(y, -4)) + 1 / (1 + Math.pow(z, -4)));
                    return 1.0 / (1.0 + 10 / (x * x * x * x)) + 1.0 / (1.0 + 1.0 / (y * y * y * y)) + 1.0 / (1.0 + 1.0 / (z * z * z * z));
                case KORNS1:
                    return 1.57 + (24.3 * xs[3]);
                case KORNS2:
                    return 0.23 + (14.2 * ((xs[3] + xs[1]) / (3.0 * xs[4])));
                case KORNS3:
                    return -5.41 + (4.9 * (((xs[3] - xs[0]) + (xs[1] / xs[4])) / (3 * xs[4])));
                case KORNS4:
                    return -2.3 + (0.13 * Math.Sin(xs[2]));
                case KORNS5:
                    return 3.0 + (2.13 * Math.Log(xs[4]));
                case KORNS6:
                    return 1.3 + (0.13 * Math.Sqrt(xs[0]));
                case KORNS7:
                    return 213.80940889 - (213.80940889 * Math.Exp(-0.54723748542 * xs[0]));
                case KORNS8:
                    return 6.87 + (11.0 * Math.Sqrt(7.23 * xs[0] * xs[3] * xs[4]));
                case KORNS9:
                    return Math.Sqrt(xs[0]) / Math.Log(xs[1]) * Math.Exp(xs[2] / (xs[3] * xs[3]));
                case KORNS10:
                    return 0.81 + (24.3 * (((2.0 * xs[1]) + (3.0 * (xs[2] * xs[2]))) / ((4.0 * (xs[3] * xs[3] * xs[3])) + (5.0 * (xs[4] * xs[4] * xs[4] * xs[4])))));
                case KORNS11:
                    return 6.87 + (11.0 * Math.Cos(7.23 * xs[0] * xs[0] * xs[0]));
                case KORNS12:
                    return 2.0 - (2.1 * (Math.Cos(9.8 * xs[0]) * Math.Sin(1.3 * xs[4])));
                case KORNS13:
                    return 32.0 - (3.0 * ((Math.Tan(xs[0]) / Math.Tan(xs[1])) * (Math.Tan(xs[2]) / Math.Tan(xs[3]))));
                case KORNS14:
                    return 22.0 - (4.2 * ((Math.Cos(xs[0]) - Math.Tan(xs[1])) * (Math.Tanh(xs[2]) / Math.Sin(xs[3]))));
                case KORNS15:
                    return 12.0 - (6.0 * ((Math.Tan(xs[0]) / Math.Exp(xs[1])) * (Math.Log(xs[2]) - Math.Tan(xs[3]))));
                case KEIJZER1:  // fall thru
                case KEIJZER2:  // fall thru
                case KEIJZER3:
                    return 0.3 * x * Math.Sin(2 * Math.PI * x);
                case KEIJZER4:
                    return x * x * x * Math.Exp(-x) * Math.Cos(x) * Math.Sin(x) * (Math.Sin(x) * Math.Sin(x) * Math.Cos(x) - 1);
                case KEIJZER5:
                    return (30.0 * x * z) / ((x - 10.0) * y * y);
                case KEIJZER6:
                    {
                        var sum = 0.0;
                        var fx = Math.Floor(x);
                        for (var i = 1; i < fx + 1; i++)  // up to and including floor(x)
                            sum += (1.0 / i);
                        return sum;
                    }
                case KEIJZER7:                          // Note this presumes you don't have log(x) in your function set!
                    return Math.Log(x);
                case KEIJZER8:                          // same as NGUYEN8
                    return Math.Sqrt(x);
                case KEIJZER9:
                    return asinh(x);   // Not a function in Math
                case KEIJZER10:
                    return Math.Pow(x, y);  // same as NGUYEN11
                case KEIJZER11:
                    return x * y + Math.Sin((x - 1.0) * (y - 1.0));
                case KEIJZER12:
                    return x * x * x * x - x * x * x + y * y / 2.0 - y;
                case KEIJZER13:
                    return 6.0 * Math.Sin(x) * Math.Cos(y);
                case KEIJZER14:
                    return 8.0 / (2.0 + x * x + y * y);
                case KEIJZER15:
                    return x * x * x / 5.0 + y * y * y / 2.0 - y - x;
                case VLADISLAVLEVA1:
                    return Math.Exp(-(x - 1) * (x - 1)) / (1.2 + (y - 2.5) * (y - 2.5));
                case VLADISLAVLEVA2:
                    return Math.Exp(-x) * x * x * x * Math.Cos(x) * Math.Sin(x) * (Math.Cos(x) * Math.Sin(x) * Math.Sin(x) - 1);
                case VLADISLAVLEVA3:
                    return Math.Exp(-x) * x * x * x * Math.Cos(x) * Math.Sin(x) * (Math.Cos(x) * Math.Sin(x) * Math.Sin(x) - 1) * (y - 5);
                case VLADISLAVLEVA4:
                    {
                        double sum = 0;
                        for (var i = 0; i < 5; i++)
                            sum += (xs[i] - 3) * (xs[i] - 3);
                        return 10.0 / (5.0 + sum);
                    }
                case VLADISLAVLEVA5:
                    return (30.0 * (x - 1.0) * (z - 1.0)) / (y * y * (x - 10.0));
                case VLADISLAVLEVA6:
                    return 6.0 * Math.Sin(x) * Math.Cos(y);
                case VLADISLAVLEVA7:
                    return (x - 3.0) * (y - 3.0) + 2 * Math.Sin((x - 4.0) * (y - 4.0));
                case VLADISLAVLEVA8:
                    return ((x - 3.0) * (x - 3.0) * (x - 3.0) * (x - 3.0) + (y - 3.0) * (y - 3.0) * (y - 3.0) - (y - 3.0)) / ((y - 2.0) * (y - 2.0) * (y - 2.0) * (y - 2.0) + 10.0);
                default:
                    throw new ArgumentException("Invalid benchmark value " + benchmark);
            }
            // never reaches here
        }

        /* Hyperbolic Arc Sin -- not standard in Java Math library */
        static double asinh(double x)
        {
            return Math.Log(x + Math.Sqrt(x * x + 1.0));
        }

        #endregion // Input Sample Generation

        #region Computation of delta error between expected value and provided value

        const double PROBABLY_ZERO = 1.11E-15;
        const double BIG_NUMBER = 1.0e15;                // the same as lilgp uses

        /* Returns the error between the result and the expected result of a single
            data point. */
        public double error(double result, double expectedResult)
        {
            double delta = Math.Abs(result - expectedResult);

            // It's possible to get NaN because cos(infinity) and
            // sin(infinity) are undefined (hence cos(exp(3000)) zings ya!)
            // So since NaN is NOT =,<,>,etc. any other number, including
            // NaN, we're CAREFULLY wording our cutoff to include NaN.

            if (!(delta < BIG_NUMBER))   // *NOT* (delta >= BIG_NUMBER)
                delta = BIG_NUMBER;

            // very slight math errors can creep in when evaluating
            // two equivalent by differently-ordered functions, like
            // x * (x*x*x + x*x)  vs. x*x*x*x + x*x
            // So we're assuming that very small values are actually zero

            else if (delta < PROBABLY_ZERO)  // slightly off
                delta = 0.0;
            return delta;
        }

        #endregion // Computation of delta error between expected value and provided value

        #region Setup

        // parameters
        public const String P_TESTING_FILE = "testing-file";
        public const String P_TRAINING_FILE = "training-file";
        public const String P_PROBLEM_TYPE = "type";

        public double[] currentValue;

        // these are read-only during evaluation-time, so
        // they can be just light-cloned and not deep cloned.
        // cool, huh?

        public double[][] trainingInputs;
        public double[] trainingOutputs;
        public double[][] testingInputs;
        public double[] testingOutputs;

        // we'll need to deep clone this one though.
        public RegressionData data;

        public override Object Clone()
        {
            // don't bother copying the inputs and outputs; they're read-only :-)
            // don't bother copying the current value, it's only set during evaluation
            // but we need to copy our regression data        
            var myobj = (Benchmarks)(base.Clone());
            myobj.data = (RegressionData)(data.Clone());
            return myobj;
        }

        public override void Setup(IEvolutionState state, IParameter paramBase)
        {
            // very important, remember this
            base.Setup(state, paramBase);

            // should we load our x parameters from a file, or generate them randomly?
            var training_file = state.Parameters.GetResource(paramBase.Push(P_TRAINING_FILE), null);
            var testing_file = state.Parameters.GetResource(paramBase.Push(P_TESTING_FILE), null);
            var problem = state.Parameters.GetString(paramBase.Push(P_PROBLEM_TYPE), null);
            var benchmark = -1;

            if (problem == null)
            {
                state.Output.Message("Loading benchmark data from files");
                if ((testing_file == null || training_file == null))            // must provide both
                {
                    state.Output.Fatal("If you don't specify a problem type, you must provide a training file and a testing file",
                        (training_file == null ? paramBase.Push(P_TRAINING_FILE) : paramBase.Push(P_TESTING_FILE)));
                }
                else  // load from files
                {
                    try
                    {
                        int numInputs = 0;

                        // first load the number of input variables
                        var scan = new Scanner(training_file);
                        if (scan.HasNextInt())
                            numInputs = scan.NextInt();
                        else state.Output.Fatal("Number of input variables not provided at beginning of training file ", paramBase.Push(P_TRAINING_FILE), null);

                        // Load into an array list each element
                        var input = new List<double[]>();
                        var output = new List<double>();
                        while (scan.HasNextDouble())
                        {
                            var in_ = new double[numInputs];
                            var out_ = 0.0;
                            for (var i = 0; i < numInputs; i++)
                            {
                                if (scan.HasNextDouble())
                                    in_[i] = scan.NextDouble();
                                else state.Output.Fatal("Non-normal number of data points in training file ", paramBase.Push(P_TRAINING_FILE), null);
                            }
                            if (scan.HasNextDouble())
                                out_ = scan.NextDouble();
                            else state.Output.Fatal("Non-normal number of data points in training file ", paramBase.Push(P_TRAINING_FILE), null);
                            input.Add(in_);
                            output.Add(out_);
                        }

                        // dump to arrays
                        var len = input.Count;
                        trainingInputs = new double[len][];
                        for (var i = 0; i < len; i++)
                            trainingInputs[i] = new double[numInputs];
                        trainingOutputs = new double[len];
                        for (var i = 0; i < len; i++)
                        {
                            trainingInputs[i] = input[i];
                            trainingOutputs[i] = output[i];
                        }


                        // same thing for testing


                        scan = new Scanner(testing_file);
                        if (scan.HasNextInt())
                            numInputs = scan.NextInt();
                        else state.Output.Fatal("Number of input variables not provided at beginning of testing file ", paramBase.Push(P_TESTING_FILE), null);

                        // Load into an array list each element
                        input = new List<double[]>();
                        output = new List<double>();
                        while (scan.HasNextDouble())
                        {
                            var in_ = new double[numInputs];
                            var out_ = 0.0;
                            for (var i = 0; i < numInputs; i++)
                            {
                                if (scan.HasNextDouble())
                                    in_[i] = scan.NextDouble();
                                else state.Output.Fatal("Non-normal number of data points in testing file ", paramBase.Push(P_TESTING_FILE), null);
                            }
                            if (scan.HasNextDouble())
                                out_ = scan.NextDouble();
                            else state.Output.Fatal("Non-normal number of data points in testing file ", paramBase.Push(P_TESTING_FILE), null);
                            input.Add(in_);
                            output.Add(out_);
                        }

                        // dump to arrays
                        len = input.Count;
                        testingInputs = new double[len][];
                        for (var i = 0; i < len; i++)
                            testingInputs[i] = new double[numInputs];
                        testingOutputs = new double[len];
                        for (var i = 0; i < len; i++)
                        {
                            testingInputs[i] = input[i];
                            testingOutputs[i] = output[i];
                        }
                    }
                    catch (FormatException e)
                    {
                        state.Output.Fatal("Some tokens in the file were not numbers.");
                    }
                }
            }
            else
            {
                // determine benchmark
                for (var i = 0; i < names.Length; i++)
                    if (names[i].Equals(problem))  // got it
                    { benchmark = i; break; }
                if (benchmark == -1) // uh oh
                    state.Output.Fatal("Could not find benchmark " + problem, paramBase.Push(P_PROBLEM_TYPE), null);

                state.Output.Message("Doing benchmark " + names[benchmark]);

                try
                {
                    trainingInputs = trainPoints(state, benchmark, 0);
                    trainingOutputs = new double[trainingInputs.Length];
                    for (var i = 0; i < trainingOutputs.Length; i++)
                        trainingOutputs[i] = func(state, trainingInputs[i], benchmark);
                }
                catch (ArgumentException e)
                {
                    state.Output.Fatal("Error in generating training data: " + e.Message);
                }

                try
                {
                    testingInputs = testPoints(state, benchmark, 0, trainingInputs);
                    testingOutputs = new double[testingInputs.Length];
                    for (var i = 0; i < testingOutputs.Length; i++)
                        testingOutputs[i] = func(state, testingInputs[i], benchmark);
                }
                catch (ArgumentException e)
                {
                    state.Output.Fatal("Error in generating testing data: " + e.Message);
                }

            }


            var param = new Parameter("gp.tc.0.fset");  // we assume we have a single tree
            var pval = state.Parameters.GetString(param, null);

            // verify the number of variables match the expected function set
            if (problem == null)  // it's being loaded from file
            {
                var found = false;
                var vars = fs_vars[trainingInputs[0].Length];
                for (var i = 0; i < vars.Length; i++)
                    if (pval.Equals(vars[i])) { found = true; break; }
                if (!found)
                    state.Output.Warning("The number of variables in your problem data (" + trainingInputs[0].Length +
                        "does not match the variables found in the function set " + pval + ".  Hope you know what you're doing.",
                        param);
                else state.Output.Message("Using function set " + pval);
            }
            else
            {
                if (!(pval.Equals(fs[benchmark])))  // uh oh
                    state.Output.Warning("The number of variables for the " + names[benchmark] +
                        " problem (" + trainingInputs[0].Length +
                        ") is normally handled by the function set " + fs[benchmark] +
                        " but you are using " + pval + ".  Hope you know what you're doing.  " +
                        "To correct this, try adding the parameter gp.tc.0.fset=" + fs[benchmark],
                        param);
                else state.Output.Message("Using function set " + pval);
            }

            // set up our input -- don't want to use the default base, it's unsafe
            data = (RegressionData)state.Parameters.GetInstanceForParameterEq(paramBase.Push(P_DATA), null, typeof(RegressionData));
            data.Setup(state, paramBase.Push(P_DATA));
        }

        #endregion // Setup

        #region Evaluation.  evaluate(...) uses training cases, and Describe(...) uses testing cases

        public void Evaluate(IEvolutionState state, Individual ind, int subpopulation, int threadnum)
        {
            if (!ind.Evaluated)  // don't bother reevaluating
            {
                var hits = 0;
                var sum = 0.0;
                for (var y = 0; y < trainingInputs.Length; y++)
                {
                    currentValue = trainingInputs[y];
                    ((GPIndividual)ind).Trees[0].Child.Eval(
                        state, threadnum, data, Stack, ((GPIndividual)ind), this);

                    var err = error(data.x, trainingOutputs[y]);

                    // We'll keep the auxillary hits measure for tradition only 
                    const double HIT_LEVEL = 0.01;
                    if (err <= HIT_LEVEL) hits++;

                    sum += err;
                }

                // the fitness better be KozaFitness!
                var f = (KozaFitness)ind.Fitness;
                f.SetStandardizedFitness(state, sum);
                f.Hits = hits;
                ind.Evaluated = true;
            }
        }

        public void Describe(EvolutionState state, Individual ind, int subpopulation, int threadnum, int log)
        {
            // we do the testing set here

            state.Output.PrintLn("\n\nPerformance of Best Individual on Testing Set:\n", log);

            var hits = 0;
            var sum = 0.0;
            for (var y = 0; y < testingInputs.Length; y++)
            {
                currentValue = testingInputs[y];
                ((GPIndividual)ind).Trees[0].Child.Eval(state, threadnum, data, Stack, (GPIndividual)ind, this);

                var err = error(data.x, testingOutputs[y]);

                // We'll keep the auxillary hits measure for tradition only 
                const double HIT_LEVEL = 0.01;
                if (err <= HIT_LEVEL) hits++;

                sum += err;
            }

            // the fitness better be KozaFitness!
            var f = (KozaFitness)ind.Fitness.Clone();     // make a copy, we're just printing it out
            f.SetStandardizedFitness(state, sum);
            f.Hits = hits;

            f.PrintFitnessForHumans(state, log);
        }

        #endregion // Evaluation.  evaluate(...) uses training cases, and Describe(...) uses testing cases
    }
}